{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Training Model from Scratch\nLisa Fung, 05/14/2024\n\nFollowing Andrej Karpathyâ€™s Recipe to Training Neural Networks: https://karpathy.github.io/2019/04/25/recipe/","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom sklearn.preprocessing import StandardScaler\n\nfrom torchvision.io import read_image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-23T03:20:35.847398Z","iopub.execute_input":"2024-05-23T03:20:35.847811Z","iopub.status.idle":"2024-05-23T03:20:44.212791Z","shell.execute_reply.started":"2024-05-23T03:20:35.847775Z","shell.execute_reply":"2024-05-23T03:20:44.211272Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/planttraits2024\"\ndf = pd.read_csv(f'{BASE_PATH}/train.csv') # Ancillary geodata\ndf['image_path'] = f'{BASE_PATH}/train_images/'+df['id'].astype(str)+'.jpeg' # Image path","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:20:44.214793Z","iopub.execute_input":"2024-05-23T03:20:44.215687Z","iopub.status.idle":"2024-05-23T03:20:46.940006Z","shell.execute_reply.started":"2024-05-23T03:20:44.215652Z","shell.execute_reply":"2024-05-23T03:20:46.938883Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Borrowed from Plant Traits Sample Notebook\nclass CFG:\n    verbose = 1  # Verbosity\n    seed = 42  # Random seed\n    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n    image_size = [224, 224]  # Input image size\n    epochs = 12 # Training epochs\n    batch_size = 96  # Batch size\n    lr_mode = \"step\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n    drop_remainder = True  # Drop incomplete batches\n    num_classes = 6 # Number of classes in the dataset\n    num_folds = 5 # Number of folds to split the dataset\n    fold = 0 # Which fold to set as validation data\n    class_names = ['X4_mean', 'X11_mean', 'X18_mean',\n                   'X26_mean', 'X50_mean', 'X3112_mean',]\n    aux_class_names = list(map(lambda x: x.replace(\"mean\",\"sd\"), class_names))\n    num_classes = len(class_names)\n    aux_num_classes = len(aux_class_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:20:46.941414Z","iopub.execute_input":"2024-05-23T03:20:46.942308Z","iopub.status.idle":"2024-05-23T03:20:46.950958Z","shell.execute_reply.started":"2024-05-23T03:20:46.942275Z","shell.execute_reply":"2024-05-23T03:20:46.949547Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Train/Validation Split\nBorrowed from Plant Traits Sample Notebook","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=42)\n\n# Create separate bin for each traits\nfor i, trait in enumerate(CFG.class_names):\n\n    # Determine the bin edges dynamically based on the distribution of traits\n    bin_edges = np.percentile(df[trait], np.linspace(0, 100, CFG.num_folds + 1))\n    df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n\n# Concatenate the bins into a final bin\ndf[\"final_bin\"] = (\n    df[[f\"bin_{i}\" for i in range(len(CFG.class_names))]]\n    .astype(str)\n    .agg(\"\".join, axis=1)\n)\n\n# Perform the stratified split using final bin\ndf = df.reset_index(drop=True)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n    df.loc[valid_idx, \"fold\"] = fold","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:20:46.954074Z","iopub.execute_input":"2024-05-23T03:20:46.954440Z","iopub.status.idle":"2024-05-23T03:20:48.401989Z","shell.execute_reply.started":"2024-05-23T03:20:46.954414Z","shell.execute_reply":"2024-05-23T03:20:48.400808Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = df[df[\"fold\"] != 0]\nvalid_df = df[df[\"fold\"] == 0] # Fold 0 is validation\ntrain_df[CFG.class_names + [\"fold\"]].describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:20:48.404996Z","iopub.execute_input":"2024-05-23T03:20:48.405463Z","iopub.status.idle":"2024-05-23T03:20:48.537825Z","shell.execute_reply.started":"2024-05-23T03:20:48.405425Z","shell.execute_reply":"2024-05-23T03:20:48.536380Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            X4_mean      X11_mean      X18_mean      X26_mean       X50_mean  \\\ncount  44391.000000  4.439100e+04  4.439100e+04  4.439100e+04   44391.000000   \nmean       0.522456  1.271709e+02  2.460040e+04  3.096704e+03      12.810444   \nstd        0.176001  1.237979e+04  2.582362e+06  2.210436e+05    1313.424294   \nmin       -2.431157  6.780000e-05  2.330000e-08  5.500000e-07       0.000097   \n25%        0.410739  1.063560e+01  3.099867e-01  5.595144e-01       1.174045   \n50%        0.509275  1.512003e+01  7.171231e-01  2.529542e+00       1.480130   \n75%        0.622427  1.968705e+01  3.574691e+00  1.498396e+01       1.924787   \nmax        4.475172  1.504254e+06  2.720494e+08  3.106555e+07  159759.897700   \n\n         X3112_mean          fold  \ncount  4.439100e+04  44391.000000  \nmean   4.938293e+05      2.499966  \nstd    1.023270e+08      1.118037  \nmin    7.690000e-08      1.000000  \n25%    2.552807e+02      1.500000  \n50%    7.258266e+02      2.000000  \n75%    2.158052e+03      3.000000  \nmax    2.155911e+10      4.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X4_mean</th>\n      <th>X11_mean</th>\n      <th>X18_mean</th>\n      <th>X26_mean</th>\n      <th>X50_mean</th>\n      <th>X3112_mean</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>44391.000000</td>\n      <td>4.439100e+04</td>\n      <td>4.439100e+04</td>\n      <td>4.439100e+04</td>\n      <td>44391.000000</td>\n      <td>4.439100e+04</td>\n      <td>44391.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.522456</td>\n      <td>1.271709e+02</td>\n      <td>2.460040e+04</td>\n      <td>3.096704e+03</td>\n      <td>12.810444</td>\n      <td>4.938293e+05</td>\n      <td>2.499966</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.176001</td>\n      <td>1.237979e+04</td>\n      <td>2.582362e+06</td>\n      <td>2.210436e+05</td>\n      <td>1313.424294</td>\n      <td>1.023270e+08</td>\n      <td>1.118037</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-2.431157</td>\n      <td>6.780000e-05</td>\n      <td>2.330000e-08</td>\n      <td>5.500000e-07</td>\n      <td>0.000097</td>\n      <td>7.690000e-08</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.410739</td>\n      <td>1.063560e+01</td>\n      <td>3.099867e-01</td>\n      <td>5.595144e-01</td>\n      <td>1.174045</td>\n      <td>2.552807e+02</td>\n      <td>1.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.509275</td>\n      <td>1.512003e+01</td>\n      <td>7.171231e-01</td>\n      <td>2.529542e+00</td>\n      <td>1.480130</td>\n      <td>7.258266e+02</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.622427</td>\n      <td>1.968705e+01</td>\n      <td>3.574691e+00</td>\n      <td>1.498396e+01</td>\n      <td>1.924787</td>\n      <td>2.158052e+03</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.475172</td>\n      <td>1.504254e+06</td>\n      <td>2.720494e+08</td>\n      <td>3.106555e+07</td>\n      <td>159759.897700</td>\n      <td>2.155911e+10</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Pre-Process Data\nFor each trait, we apply a combination of the following pre-processing techniques depending on the specific distribution of the trait's values. The pre-processing ONLY APPLIES to **training data** (NOT validation data), so we ignore fold 0.\n1. Remove outliers by filtering for the quantile range (0.005, 0.995) (for all traits)\n2. Use log base 10 transformation of right-skewed data (for all traits except trait X4)\n3. Normalize data to have mean = 0 and standard deviation = 1 (for all traits)","metadata":{}},{"cell_type":"code","source":"class PlantDataPreProcess:\n    lower_quantile = 0.005\n    upper_quantile = 0.995\n    log_transform = np.log10","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:20:48.539632Z","iopub.execute_input":"2024-05-23T03:20:48.539945Z","iopub.status.idle":"2024-05-23T03:20:48.545370Z","shell.execute_reply.started":"2024-05-23T03:20:48.539919Z","shell.execute_reply":"2024-05-23T03:20:48.544117Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Filter data\nprint(\"Num samples before filering:\", len(train_df))\n\nfor trait in CFG.class_names:\n    lower_bound = train_df[trait].quantile(PlantDataPreProcess.lower_quantile)\n    upper_bound = train_df[trait].quantile(PlantDataPreProcess.upper_quantile)\n    train_df = train_df[(train_df[trait] >= lower_bound) & (train_df[trait] <= upper_bound)]\n    \nprint(\"Num samples After filtering:\", len(train_df))\ntrain_df[CFG.class_names].describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:20:48.546787Z","iopub.execute_input":"2024-05-23T03:20:48.547259Z","iopub.status.idle":"2024-05-23T03:20:48.793261Z","shell.execute_reply.started":"2024-05-23T03:20:48.547204Z","shell.execute_reply":"2024-05-23T03:20:48.791905Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Num samples before filering: 44391\nNum samples After filtering: 41799\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            X4_mean      X11_mean      X18_mean      X26_mean      X50_mean  \\\ncount  41799.000000  41799.000000  41799.000000  41799.000000  41799.000000   \nmean       0.521677     15.822802      3.207161     42.242341      1.616606   \nstd        0.144269      7.598820      5.347785    166.643061      0.638061   \nmin        0.176725      2.830246      0.032735      0.006451      0.494166   \n25%        0.410762     10.792842      0.318074      0.585903      1.186274   \n50%        0.509045     15.127512      0.714281      2.534105      1.481558   \n75%        0.621267     19.509902      3.402668     14.288584      1.909773   \nmax        0.957788     58.287012     32.388908   2369.101479      4.608223   \n\n         X3112_mean  \ncount  41799.000000  \nmean    1858.228362  \nstd     3116.096582  \nmin        9.725925  \n25%      267.237330  \n50%      729.941079  \n75%     2106.917500  \nmax    29876.601410  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X4_mean</th>\n      <th>X11_mean</th>\n      <th>X18_mean</th>\n      <th>X26_mean</th>\n      <th>X50_mean</th>\n      <th>X3112_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.521677</td>\n      <td>15.822802</td>\n      <td>3.207161</td>\n      <td>42.242341</td>\n      <td>1.616606</td>\n      <td>1858.228362</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.144269</td>\n      <td>7.598820</td>\n      <td>5.347785</td>\n      <td>166.643061</td>\n      <td>0.638061</td>\n      <td>3116.096582</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.176725</td>\n      <td>2.830246</td>\n      <td>0.032735</td>\n      <td>0.006451</td>\n      <td>0.494166</td>\n      <td>9.725925</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.410762</td>\n      <td>10.792842</td>\n      <td>0.318074</td>\n      <td>0.585903</td>\n      <td>1.186274</td>\n      <td>267.237330</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.509045</td>\n      <td>15.127512</td>\n      <td>0.714281</td>\n      <td>2.534105</td>\n      <td>1.481558</td>\n      <td>729.941079</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.621267</td>\n      <td>19.509902</td>\n      <td>3.402668</td>\n      <td>14.288584</td>\n      <td>1.909773</td>\n      <td>2106.917500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.957788</td>\n      <td>58.287012</td>\n      <td>32.388908</td>\n      <td>2369.101479</td>\n      <td>4.608223</td>\n      <td>29876.601410</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Log10 transformation for all traits except X4\ny_train = train_df[CFG.class_names]\n\nfor skewed_trait in CFG.class_names[1:]:\n    y_train.loc[:, skewed_trait] = y_train[skewed_trait].apply(PlantDataPreProcess.log_transform)\n    \ny_train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:20:49.954403Z","iopub.execute_input":"2024-05-23T03:20:49.955873Z","iopub.status.idle":"2024-05-23T03:20:50.012437Z","shell.execute_reply.started":"2024-05-23T03:20:49.955817Z","shell.execute_reply":"2024-05-23T03:20:50.011174Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            X4_mean      X11_mean      X18_mean      X26_mean      X50_mean  \\\ncount  41799.000000  41799.000000  41799.000000  41799.000000  41799.000000   \nmean       0.521677      1.147506      0.002329      0.456349      0.177628   \nstd        0.144269      0.221707      0.667658      1.036389      0.163305   \nmin        0.176725      0.451824     -1.484983     -2.190374     -0.306127   \n25%        0.410762      1.033136     -0.497472     -0.232174      0.074185   \n50%        0.509045      1.179768     -0.146131      0.403825      0.170719   \n75%        0.621267      1.290255      0.531820      1.154989      0.280982   \nmax        0.957788      1.765572      1.510396      3.374584      0.663534   \n\n         X3112_mean  \ncount  41799.000000  \nmean       2.853320  \nstd        0.645702  \nmin        0.987931  \n25%        2.426897  \n50%        2.863288  \n75%        3.323648  \nmax        4.475331  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X4_mean</th>\n      <th>X11_mean</th>\n      <th>X18_mean</th>\n      <th>X26_mean</th>\n      <th>X50_mean</th>\n      <th>X3112_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n      <td>41799.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.521677</td>\n      <td>1.147506</td>\n      <td>0.002329</td>\n      <td>0.456349</td>\n      <td>0.177628</td>\n      <td>2.853320</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.144269</td>\n      <td>0.221707</td>\n      <td>0.667658</td>\n      <td>1.036389</td>\n      <td>0.163305</td>\n      <td>0.645702</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.176725</td>\n      <td>0.451824</td>\n      <td>-1.484983</td>\n      <td>-2.190374</td>\n      <td>-0.306127</td>\n      <td>0.987931</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.410762</td>\n      <td>1.033136</td>\n      <td>-0.497472</td>\n      <td>-0.232174</td>\n      <td>0.074185</td>\n      <td>2.426897</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.509045</td>\n      <td>1.179768</td>\n      <td>-0.146131</td>\n      <td>0.403825</td>\n      <td>0.170719</td>\n      <td>2.863288</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.621267</td>\n      <td>1.290255</td>\n      <td>0.531820</td>\n      <td>1.154989</td>\n      <td>0.280982</td>\n      <td>3.323648</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.957788</td>\n      <td>1.765572</td>\n      <td>1.510396</td>\n      <td>3.374584</td>\n      <td>0.663534</td>\n      <td>4.475331</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Normalize to mean = 0, std dev = 1\nfrom sklearn.preprocessing import StandardScaler\n\nSCALER = StandardScaler()\ny_train = SCALER.fit_transform(y_train)\n\ny_train_df = pd.DataFrame(y_train, columns=CFG.class_names)\ny_train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T03:21:02.018251Z","iopub.execute_input":"2024-05-23T03:21:02.018702Z","iopub.status.idle":"2024-05-23T03:21:02.068888Z","shell.execute_reply.started":"2024-05-23T03:21:02.018667Z","shell.execute_reply":"2024-05-23T03:21:02.067772Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            X4_mean      X11_mean      X18_mean      X26_mean      X50_mean  \\\ncount  4.179900e+04  4.179900e+04  4.179900e+04  4.179900e+04  4.179900e+04   \nmean  -5.490689e-17 -3.829883e-16 -3.357310e-17  1.699904e-19  1.031842e-16   \nstd    1.000012e+00  1.000012e+00  1.000012e+00  1.000012e+00  1.000012e+00   \nmin   -2.391054e+00 -3.137878e+00 -2.227683e+00 -2.553825e+00 -2.962323e+00   \n25%   -7.688166e-01 -5.158674e-01 -7.485979e-01 -6.643567e-01 -6.334448e-01   \n50%   -8.755688e-02  1.455159e-01 -2.223625e-01 -5.068134e-02 -4.231292e-02   \n75%    6.903150e-01  6.438710e-01  7.930659e-01  6.741179e-01  6.328929e-01   \nmax    3.022934e+00  2.787790e+00  2.258770e+00  2.815806e+00  2.975485e+00   \n\n         X3112_mean  \ncount  4.179900e+04  \nmean  -4.310956e-16  \nstd    1.000012e+00  \nmin   -2.888967e+00  \n25%   -6.604100e-01  \n50%    1.543735e-02  \n75%    7.284061e-01  \nmax    2.512043e+00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X4_mean</th>\n      <th>X11_mean</th>\n      <th>X18_mean</th>\n      <th>X26_mean</th>\n      <th>X50_mean</th>\n      <th>X3112_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4.179900e+04</td>\n      <td>4.179900e+04</td>\n      <td>4.179900e+04</td>\n      <td>4.179900e+04</td>\n      <td>4.179900e+04</td>\n      <td>4.179900e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-5.490689e-17</td>\n      <td>-3.829883e-16</td>\n      <td>-3.357310e-17</td>\n      <td>1.699904e-19</td>\n      <td>1.031842e-16</td>\n      <td>-4.310956e-16</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000012e+00</td>\n      <td>1.000012e+00</td>\n      <td>1.000012e+00</td>\n      <td>1.000012e+00</td>\n      <td>1.000012e+00</td>\n      <td>1.000012e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-2.391054e+00</td>\n      <td>-3.137878e+00</td>\n      <td>-2.227683e+00</td>\n      <td>-2.553825e+00</td>\n      <td>-2.962323e+00</td>\n      <td>-2.888967e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-7.688166e-01</td>\n      <td>-5.158674e-01</td>\n      <td>-7.485979e-01</td>\n      <td>-6.643567e-01</td>\n      <td>-6.334448e-01</td>\n      <td>-6.604100e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-8.755688e-02</td>\n      <td>1.455159e-01</td>\n      <td>-2.223625e-01</td>\n      <td>-5.068134e-02</td>\n      <td>-4.231292e-02</td>\n      <td>1.543735e-02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.903150e-01</td>\n      <td>6.438710e-01</td>\n      <td>7.930659e-01</td>\n      <td>6.741179e-01</td>\n      <td>6.328929e-01</td>\n      <td>7.284061e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.022934e+00</td>\n      <td>2.787790e+00</td>\n      <td>2.258770e+00</td>\n      <td>2.815806e+00</td>\n      <td>2.975485e+00</td>\n      <td>2.512043e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## View Data","metadata":{}},{"cell_type":"code","source":"df.columns.to_list()\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:15:37.097121Z","iopub.execute_input":"2024-05-19T19:15:37.098166Z","iopub.status.idle":"2024-05-19T19:15:37.812677Z","shell.execute_reply.started":"2024-05-19T19:15:37.098128Z","shell.execute_reply":"2024-05-19T19:15:37.811569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get images\ndef decode_image(inp, image_row):\n    path = inp.loc[image_row, \"image_path\"]\n\n    # Read jpeg image\n    image = read_image(path)\n    return image.permute(1, 2, 0)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:15:47.276653Z","iopub.execute_input":"2024-05-19T19:15:47.277055Z","iopub.status.idle":"2024-05-19T19:15:47.283288Z","shell.execute_reply.started":"2024-05-19T19:15:47.277022Z","shell.execute_reply":"2024-05-19T19:15:47.281790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check Annual Mean Temperature below 0 degrees C","metadata":{}},{"cell_type":"code","source":"# Get all images with very low annual mean temperature\nbelow_0_temp_idx = df.index[df['WORLDCLIM_BIO1_annual_mean_temperature'] < 0]\nlen(below_0_temp_idx)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:15:48.932089Z","iopub.execute_input":"2024-05-19T19:15:48.933023Z","iopub.status.idle":"2024-05-19T19:15:48.941774Z","shell.execute_reply.started":"2024-05-19T19:15:48.932986Z","shell.execute_reply":"2024-05-19T19:15:48.940554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check images\nfig = plt.figure()\n\nfor i in range(20):\n    fig.add_subplot(4, 5, i+1) \n    plt.imshow(decode_image(df, below_0_temp_idx[i]))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:15:50.829097Z","iopub.execute_input":"2024-05-19T19:15:50.829522Z","iopub.status.idle":"2024-05-19T19:15:54.788336Z","shell.execute_reply.started":"2024-05-19T19:15:50.829488Z","shell.execute_reply":"2024-05-19T19:15:54.786941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check Variation in Labels (Plant Traits)","metadata":{}},{"cell_type":"code","source":"# Check variation of labels\n# regex guide: https://www.w3schools.com/python/python_regex.asp\ndf.filter(regex=\"^X.+_mean$\").describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:15:54.790201Z","iopub.execute_input":"2024-05-19T19:15:54.791392Z","iopub.status.idle":"2024-05-19T19:15:54.847473Z","shell.execute_reply.started":"2024-05-19T19:15:54.791334Z","shell.execute_reply":"2024-05-19T19:15:54.846217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check X11 (Leaf area per leaf dry mass) outliers","metadata":{}},{"cell_type":"code","source":"# X11: Leaf area per leaf dry mass\nprint(\"Total train samples:\", len(df))\nx11_greater_100_idx = df.index[df['X11_mean'] > 100]\nx11_less_01_idx = df.index[df['X11_mean'] < 0.1]\nprint(\"X11 > 100:\", len(x11_greater_100_idx))\nprint(\"X11 < 0.1:\", len(x11_less_01_idx))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:15:55.811286Z","iopub.execute_input":"2024-05-19T19:15:55.812681Z","iopub.status.idle":"2024-05-19T19:15:55.823456Z","shell.execute_reply.started":"2024-05-19T19:15:55.812634Z","shell.execute_reply":"2024-05-19T19:15:55.822379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check images\nfig = plt.figure()\n\nfor i in range(20):\n    fig.add_subplot(4, 5, i+1)\n    plt.imshow(decode_image(df, x11_greater_100_idx[i]))\n    \nplt.title(\"X11 greater than 100\")\n# Big leaves, very little weight","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:16:22.159756Z","iopub.execute_input":"2024-05-19T19:16:22.160171Z","iopub.status.idle":"2024-05-19T19:16:26.150636Z","shell.execute_reply.started":"2024-05-19T19:16:22.160139Z","shell.execute_reply":"2024-05-19T19:16:26.149428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check images\nfig = plt.figure()\n\nfor i in range(20):\n    fig.add_subplot(4, 5, i+1)\n    plt.imshow(decode_image(df, x11_less_01_idx[i]))\n    \nplt.title(\"X11 less than 0.1\")\n# Smaller, heavier leaves","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:16:26.152678Z","iopub.execute_input":"2024-05-19T19:16:26.153080Z","iopub.status.idle":"2024-05-19T19:16:29.803745Z","shell.execute_reply.started":"2024-05-19T19:16:26.153044Z","shell.execute_reply":"2024-05-19T19:16:29.802624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize Distributions of Each Trait","metadata":{}},{"cell_type":"code","source":"i = 2\ncol = CFG.class_names[i]\nlower = 0.005\nupper = 0.995\nlower_q = df[col].quantile(lower)\nupper_q = df[col].quantile(upper)\n\nprint(f\"Original data for trait {i}\")\nprint(df[col].describe())\nprint()\nprint(f\"Lower quantile ({lower}):\", lower_q)\nprint(f\"Upper quantile ({upper}):\", upper_q)\nprint(\"Unique values:\", len(df[col].unique()))\nprint(\"Largest unique values:\", sorted(df[col].unique(), reverse=True)[:5])\nprint()\nprint(f\"Outliers removed data for trait {i}\")\nfiltered_df = df[(df[col] >= lower_q) & (df[col] <= upper_q)][col]\ntransform_filtered_df = filtered_df.apply(np.log10)\nprint(transform_filtered_df.describe())\nprint(transform_filtered_df.hist())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:59:32.929322Z","iopub.execute_input":"2024-05-19T21:59:32.929712Z","iopub.status.idle":"2024-05-19T21:59:33.294018Z","shell.execute_reply.started":"2024-05-19T21:59:32.929681Z","shell.execute_reply":"2024-05-19T21:59:33.292723Z"},"trusted":true},"execution_count":null,"outputs":[]}]}