{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"},{"sourceId":8587982,"sourceType":"datasetVersion","datasetId":5136757}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Notebook modified from https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub.\n- Training only, EDA part not included.\n- Image model only, tabular data not used.","metadata":{}},{"cell_type":"markdown","source":"Modified from HDJOJO's original notebook with SWIN Transformer","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport imageio.v3 as imageio\nimport albumentations as A\n\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport timm\nimport glob\nimport torchmetrics\nimport time\nimport psutil\nimport os\n\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:03:19.568162Z","iopub.execute_input":"2024-06-05T05:03:19.568462Z","iopub.status.idle":"2024-06-05T05:03:19.576845Z","shell.execute_reply.started":"2024-06-05T05:03:19.568436Z","shell.execute_reply":"2024-06-05T05:03:19.575559Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Config():\n    IMAGE_SIZE = 256 #384 # Sample: [224, 224]\n#     BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n    BACKBONE = 'swinv2_tiny_window16_256'\n    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n    N_TARGETS = len(TARGET_COLUMNS)\n    BATCH_SIZE = 10 # Sample: 96\n    LR_MAX = 1e-4\n    WEIGHT_DECAY = 0.01\n    N_EPOCHS = 6 # Sample: 12\n    TRAIN_MODEL = True\n    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n    \n    DEVICE = 'cpu'\n    # Added variables\n    NUM_FOLDS = 5\n    VALID_FOLD = 0  # Fold of validation data\n        \nCONFIG = Config()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:44:55.460699Z","iopub.execute_input":"2024-06-05T05:44:55.461091Z","iopub.status.idle":"2024-06-05T05:44:55.468842Z","shell.execute_reply.started":"2024-06-05T05:44:55.461062Z","shell.execute_reply":"2024-06-05T05:44:55.467676Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Read in training data\ntrain_df = pd.read_csv('/kaggle/input/planttraits2024/train.csv')\ntrain_df['file_path'] = train_df['id'].apply(lambda s: f'/kaggle/input/planttraits2024/train_images/{s}.jpeg')\ntrain_df['jpeg_bytes'] = train_df['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n# train_df.to_pickle('train.pkl') # serialize object into string form","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:04:33.915220Z","iopub.execute_input":"2024-06-05T05:04:33.915732Z","iopub.status.idle":"2024-06-05T05:11:34.819790Z","shell.execute_reply.started":"2024-06-05T05:04:33.915695Z","shell.execute_reply":"2024-06-05T05:11:34.818670Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/55489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9463b67eacb435fae86b472d86ef6c7"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Data Filtering","metadata":{}},{"cell_type":"code","source":"# Sampled training set for faster training\nprint(\"Previous length:\", len(train_df))\n# train_df = train_df.sample(frac=0.3, random_state=42)\n# print(\"Sampled length:\", len(train_df))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:22:55.398362Z","iopub.execute_input":"2024-06-05T05:22:55.398906Z","iopub.status.idle":"2024-06-05T05:22:55.407295Z","shell.execute_reply.started":"2024-06-05T05:22:55.398870Z","shell.execute_reply":"2024-06-05T05:22:55.405854Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Previous length: 55489\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=CONFIG.NUM_FOLDS, shuffle=True, random_state=42)\n\n# Create separate bin for each traits\nfor i, trait in enumerate(CONFIG.TARGET_COLUMNS):\n    # Determine the bin edges dynamically based on the distribution of traits\n    bin_edges = np.percentile(train_df[trait], np.linspace(0, 100, CONFIG.NUM_FOLDS + 1))\n    train_df[f\"bin_{i}\"] = np.digitize(train_df[trait], bin_edges)\n\n# Concatenate the bins into a final bin\ntrain_df[\"final_bin\"] = (\n    train_df[[f\"bin_{i}\" for i in range(CONFIG.N_TARGETS)]]\n    .astype(str)\n    .agg(\"\".join, axis=1)\n)\n\n# Perform the stratified split using final bin\ntrain_df = train_df.reset_index(drop=True)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train_df, train_df[\"final_bin\"])):\n    train_df.loc[valid_idx, \"fold\"] = fold\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:22:55.683066Z","iopub.execute_input":"2024-06-05T05:22:55.683886Z","iopub.status.idle":"2024-06-05T05:22:57.226205Z","shell.execute_reply.started":"2024-06-05T05:22:55.683844Z","shell.execute_reply":"2024-06-05T05:22:57.224846Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"          id  WORLDCLIM_BIO1_annual_mean_temperature  \\\n0  192027691                               12.235703   \n1  195542235                               17.270555   \n2  196639184                               14.254504   \n3  195728812                               18.680834   \n4  195251545                                0.673204   \n\n   WORLDCLIM_BIO12_annual_precipitation  \\\n0                            374.466675   \n1                             90.239998   \n2                            902.071411   \n3                           1473.933350   \n4                            530.088867   \n\n   WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month  \\\n0                                          62.524445                       \n1                                          10.351111                       \n2                                          49.642857                       \n3                                         163.100006                       \n4                                          50.857777                       \n\n   WORLDCLIM_BIO15_precipitation_seasonality  \\\n0                                  72.256844   \n1                                  38.220940   \n2                                  17.873655   \n3                                  45.009758   \n4                                  38.230709   \n\n   WORLDCLIM_BIO4_temperature_seasonality  \\\n0                              773.592041   \n1                              859.193298   \n2                              387.977753   \n3                              381.053986   \n4                             1323.526855   \n\n   WORLDCLIM_BIO7_temperature_annual_range  SOIL_bdod_0.5cm_mean_0.01_deg  \\\n0                                33.277779                            125   \n1                                40.009777                            124   \n2                                22.807142                            107   \n3                                20.436666                            120   \n4                                45.891998                             91   \n\n   SOIL_bdod_100.200cm_mean_0.01_deg  SOIL_bdod_15.30cm_mean_0.01_deg  ...  \\\n0                                149                              136  ...   \n1                                144                              138  ...   \n2                                133                              119  ...   \n3                                131                              125  ...   \n4                                146                              120  ...   \n\n                                           file_path  \\\n0  /kaggle/input/planttraits2024/train_images/192...   \n1  /kaggle/input/planttraits2024/train_images/195...   \n2  /kaggle/input/planttraits2024/train_images/196...   \n3  /kaggle/input/planttraits2024/train_images/195...   \n4  /kaggle/input/planttraits2024/train_images/195...   \n\n                                          jpeg_bytes  bin_0  bin_1  bin_2  \\\n0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...      2      2      1   \n1  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...      3      3      2   \n2  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...      5      1      5   \n3  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...      3      2      3   \n4  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...      2      3      3   \n\n   bin_3  bin_4  bin_5  final_bin  fold  \n0      4      2      1     221421   2.0  \n1      2      2      3     332223   1.0  \n2      5      2      3     515523   0.0  \n3      2      1      3     323213   4.0  \n4      5      4      4     233544   2.0  \n\n[5 rows x 186 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>WORLDCLIM_BIO1_annual_mean_temperature</th>\n      <th>WORLDCLIM_BIO12_annual_precipitation</th>\n      <th>WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month</th>\n      <th>WORLDCLIM_BIO15_precipitation_seasonality</th>\n      <th>WORLDCLIM_BIO4_temperature_seasonality</th>\n      <th>WORLDCLIM_BIO7_temperature_annual_range</th>\n      <th>SOIL_bdod_0.5cm_mean_0.01_deg</th>\n      <th>SOIL_bdod_100.200cm_mean_0.01_deg</th>\n      <th>SOIL_bdod_15.30cm_mean_0.01_deg</th>\n      <th>...</th>\n      <th>file_path</th>\n      <th>jpeg_bytes</th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>bin_5</th>\n      <th>final_bin</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>192027691</td>\n      <td>12.235703</td>\n      <td>374.466675</td>\n      <td>62.524445</td>\n      <td>72.256844</td>\n      <td>773.592041</td>\n      <td>33.277779</td>\n      <td>125</td>\n      <td>149</td>\n      <td>136</td>\n      <td>...</td>\n      <td>/kaggle/input/planttraits2024/train_images/192...</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>221421</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>195542235</td>\n      <td>17.270555</td>\n      <td>90.239998</td>\n      <td>10.351111</td>\n      <td>38.220940</td>\n      <td>859.193298</td>\n      <td>40.009777</td>\n      <td>124</td>\n      <td>144</td>\n      <td>138</td>\n      <td>...</td>\n      <td>/kaggle/input/planttraits2024/train_images/195...</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>332223</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>196639184</td>\n      <td>14.254504</td>\n      <td>902.071411</td>\n      <td>49.642857</td>\n      <td>17.873655</td>\n      <td>387.977753</td>\n      <td>22.807142</td>\n      <td>107</td>\n      <td>133</td>\n      <td>119</td>\n      <td>...</td>\n      <td>/kaggle/input/planttraits2024/train_images/196...</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>515523</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>195728812</td>\n      <td>18.680834</td>\n      <td>1473.933350</td>\n      <td>163.100006</td>\n      <td>45.009758</td>\n      <td>381.053986</td>\n      <td>20.436666</td>\n      <td>120</td>\n      <td>131</td>\n      <td>125</td>\n      <td>...</td>\n      <td>/kaggle/input/planttraits2024/train_images/195...</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>323213</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>195251545</td>\n      <td>0.673204</td>\n      <td>530.088867</td>\n      <td>50.857777</td>\n      <td>38.230709</td>\n      <td>1323.526855</td>\n      <td>45.891998</td>\n      <td>91</td>\n      <td>146</td>\n      <td>120</td>\n      <td>...</td>\n      <td>/kaggle/input/planttraits2024/train_images/195...</td>\n      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>233544</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 186 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train = train_df[train_df[\"fold\"] != CONFIG.VALID_FOLD]\nvalid = train_df[train_df[\"fold\"] == CONFIG.VALID_FOLD] # Fold 0 is validation\ntrain[CONFIG.TARGET_COLUMNS + [\"fold\"]].describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:22:57.228280Z","iopub.execute_input":"2024-06-05T05:22:57.228650Z","iopub.status.idle":"2024-06-05T05:22:57.334986Z","shell.execute_reply.started":"2024-06-05T05:22:57.228590Z","shell.execute_reply":"2024-06-05T05:22:57.333920Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            X4_mean      X11_mean      X18_mean       X50_mean      X26_mean  \\\ncount  44391.000000  4.439100e+04  4.439100e+04   44391.000000  4.439100e+04   \nmean       0.522456  1.271709e+02  2.460040e+04      12.810444  3.096704e+03   \nstd        0.176001  1.237979e+04  2.582362e+06    1313.424294  2.210436e+05   \nmin       -2.431157  6.780000e-05  2.330000e-08       0.000097  5.500000e-07   \n25%        0.410739  1.063560e+01  3.099867e-01       1.174045  5.595144e-01   \n50%        0.509275  1.512003e+01  7.171231e-01       1.480130  2.529542e+00   \n75%        0.622427  1.968705e+01  3.574691e+00       1.924787  1.498396e+01   \nmax        4.475172  1.504254e+06  2.720494e+08  159759.897700  3.106555e+07   \n\n         X3112_mean          fold  \ncount  4.439100e+04  44391.000000  \nmean   4.938293e+05      2.499966  \nstd    1.023270e+08      1.118037  \nmin    7.690000e-08      1.000000  \n25%    2.552807e+02      1.500000  \n50%    7.258266e+02      2.000000  \n75%    2.158052e+03      3.000000  \nmax    2.155911e+10      4.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X4_mean</th>\n      <th>X11_mean</th>\n      <th>X18_mean</th>\n      <th>X50_mean</th>\n      <th>X26_mean</th>\n      <th>X3112_mean</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>44391.000000</td>\n      <td>4.439100e+04</td>\n      <td>4.439100e+04</td>\n      <td>44391.000000</td>\n      <td>4.439100e+04</td>\n      <td>4.439100e+04</td>\n      <td>44391.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.522456</td>\n      <td>1.271709e+02</td>\n      <td>2.460040e+04</td>\n      <td>12.810444</td>\n      <td>3.096704e+03</td>\n      <td>4.938293e+05</td>\n      <td>2.499966</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.176001</td>\n      <td>1.237979e+04</td>\n      <td>2.582362e+06</td>\n      <td>1313.424294</td>\n      <td>2.210436e+05</td>\n      <td>1.023270e+08</td>\n      <td>1.118037</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-2.431157</td>\n      <td>6.780000e-05</td>\n      <td>2.330000e-08</td>\n      <td>0.000097</td>\n      <td>5.500000e-07</td>\n      <td>7.690000e-08</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.410739</td>\n      <td>1.063560e+01</td>\n      <td>3.099867e-01</td>\n      <td>1.174045</td>\n      <td>5.595144e-01</td>\n      <td>2.552807e+02</td>\n      <td>1.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.509275</td>\n      <td>1.512003e+01</td>\n      <td>7.171231e-01</td>\n      <td>1.480130</td>\n      <td>2.529542e+00</td>\n      <td>7.258266e+02</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.622427</td>\n      <td>1.968705e+01</td>\n      <td>3.574691e+00</td>\n      <td>1.924787</td>\n      <td>1.498396e+01</td>\n      <td>2.158052e+03</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.475172</td>\n      <td>1.504254e+06</td>\n      <td>2.720494e+08</td>\n      <td>159759.897700</td>\n      <td>3.106555e+07</td>\n      <td>2.155911e+10</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class PlantDataPreProcess:\n    lower_quantile = 0.005\n    upper_quantile = 0.995\n    log_transform = np.log10","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:23:01.095281Z","iopub.execute_input":"2024-06-05T05:23:01.095710Z","iopub.status.idle":"2024-06-05T05:23:01.101817Z","shell.execute_reply.started":"2024-06-05T05:23:01.095680Z","shell.execute_reply":"2024-06-05T05:23:01.100252Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Filter data\nprint(\"Num samples before filtering:\", len(train))\n\nfor trait in CONFIG.TARGET_COLUMNS:\n    lower_bound = train[trait].quantile(PlantDataPreProcess.lower_quantile)\n    upper_bound = train[trait].quantile(PlantDataPreProcess.upper_quantile)\n    train = train[(train[trait] >= lower_bound) & (train[trait] <= upper_bound)]\n    \nprint(\"Num samples After filtering:\", len(train))\ntrain[CONFIG.TARGET_COLUMNS].describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:23:01.377061Z","iopub.execute_input":"2024-06-05T05:23:01.377502Z","iopub.status.idle":"2024-06-05T05:23:01.646492Z","shell.execute_reply.started":"2024-06-05T05:23:01.377460Z","shell.execute_reply":"2024-06-05T05:23:01.645381Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Num samples before filtering: 44391\nNum samples After filtering: 41797\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            X4_mean      X11_mean      X18_mean      X50_mean      X26_mean  \\\ncount  41797.000000  41797.000000  41797.000000  41797.000000  41797.000000   \nmean       0.521676     15.823053      3.207305      1.616637     42.244362   \nstd        0.144273      7.598915      5.347872      0.638061    166.646792   \nmin        0.176725      2.830246      0.032735      0.494166      0.006679   \n25%        0.410757     10.792999      0.318085      1.186312      0.586510   \n50%        0.509045     15.129038      0.714284      1.481727      2.534134   \n75%        0.621267     19.511440      3.402814      1.909787     14.288664   \nmax        0.957788     58.287012     32.388908      4.608223   2369.101479   \n\n         X3112_mean  \ncount  41797.000000  \nmean    1858.297208  \nstd     3116.155242  \nmin        9.725925  \n25%      267.237330  \n50%      729.941079  \n75%     2106.940380  \nmax    29876.601410  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X4_mean</th>\n      <th>X11_mean</th>\n      <th>X18_mean</th>\n      <th>X50_mean</th>\n      <th>X26_mean</th>\n      <th>X3112_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.521676</td>\n      <td>15.823053</td>\n      <td>3.207305</td>\n      <td>1.616637</td>\n      <td>42.244362</td>\n      <td>1858.297208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.144273</td>\n      <td>7.598915</td>\n      <td>5.347872</td>\n      <td>0.638061</td>\n      <td>166.646792</td>\n      <td>3116.155242</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.176725</td>\n      <td>2.830246</td>\n      <td>0.032735</td>\n      <td>0.494166</td>\n      <td>0.006679</td>\n      <td>9.725925</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.410757</td>\n      <td>10.792999</td>\n      <td>0.318085</td>\n      <td>1.186312</td>\n      <td>0.586510</td>\n      <td>267.237330</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.509045</td>\n      <td>15.129038</td>\n      <td>0.714284</td>\n      <td>1.481727</td>\n      <td>2.534134</td>\n      <td>729.941079</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.621267</td>\n      <td>19.511440</td>\n      <td>3.402814</td>\n      <td>1.909787</td>\n      <td>14.288664</td>\n      <td>2106.940380</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.957788</td>\n      <td>58.287012</td>\n      <td>32.388908</td>\n      <td>4.608223</td>\n      <td>2369.101479</td>\n      <td>29876.601410</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Log10 transformation for all traits except X4\nLOG_FEATURES = ['X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\ny_train = train[CONFIG.TARGET_COLUMNS]\n\nfor skewed_trait in LOG_FEATURES:\n    y_train.loc[:, skewed_trait] = y_train[skewed_trait].apply(PlantDataPreProcess.log_transform)\n\ny_train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:23:01.669261Z","iopub.execute_input":"2024-06-05T05:23:01.669697Z","iopub.status.idle":"2024-06-05T05:23:01.722625Z","shell.execute_reply.started":"2024-06-05T05:23:01.669663Z","shell.execute_reply":"2024-06-05T05:23:01.721204Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            X4_mean      X11_mean      X18_mean      X50_mean      X26_mean  \\\ncount  41797.000000  41797.000000  41797.000000  41797.000000  41797.000000   \nmean       0.521676      1.147512      0.002364      0.177637      0.456476   \nstd        0.144273      0.221711      0.667655      0.163304      1.036252   \nmin        0.176725      0.451824     -1.484983     -0.306127     -2.175279   \n25%        0.410757      1.033142     -0.497456      0.074199     -0.231724   \n50%        0.509045      1.179811     -0.146129      0.170768      0.403830   \n75%        0.621267      1.290289      0.531838      0.280985      1.154992   \nmax        0.957788      1.765572      1.510396      0.663534      3.374584   \n\n         X3112_mean  \ncount  41797.000000  \nmean       2.853331  \nstd        0.645715  \nmin        0.987931  \n25%        2.426897  \n50%        2.863288  \n75%        3.323652  \nmax        4.475331  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X4_mean</th>\n      <th>X11_mean</th>\n      <th>X18_mean</th>\n      <th>X50_mean</th>\n      <th>X26_mean</th>\n      <th>X3112_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n      <td>41797.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.521676</td>\n      <td>1.147512</td>\n      <td>0.002364</td>\n      <td>0.177637</td>\n      <td>0.456476</td>\n      <td>2.853331</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.144273</td>\n      <td>0.221711</td>\n      <td>0.667655</td>\n      <td>0.163304</td>\n      <td>1.036252</td>\n      <td>0.645715</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.176725</td>\n      <td>0.451824</td>\n      <td>-1.484983</td>\n      <td>-0.306127</td>\n      <td>-2.175279</td>\n      <td>0.987931</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.410757</td>\n      <td>1.033142</td>\n      <td>-0.497456</td>\n      <td>0.074199</td>\n      <td>-0.231724</td>\n      <td>2.426897</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.509045</td>\n      <td>1.179811</td>\n      <td>-0.146129</td>\n      <td>0.170768</td>\n      <td>0.403830</td>\n      <td>2.863288</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.621267</td>\n      <td>1.290289</td>\n      <td>0.531838</td>\n      <td>0.280985</td>\n      <td>1.154992</td>\n      <td>3.323652</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.957788</td>\n      <td>1.765572</td>\n      <td>1.510396</td>\n      <td>0.663534</td>\n      <td>3.374584</td>\n      <td>4.475331</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Normalize to mean = 0, std dev = 1\nfrom sklearn.preprocessing import StandardScaler\n\nSCALER = StandardScaler()\ny_train = SCALER.fit_transform(y_train)\n\n# Save StandardScaler\n# import pickle\n# with open('scaler.pkl','wb') as f:\n#     pickle.dump(SCALER, f)\n\n# y_train_df = pd.DataFrame(y_train, columns=CONFIG.TARGET_COLUMNS)\n# y_train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:23:03.226329Z","iopub.execute_input":"2024-06-05T05:23:03.227839Z","iopub.status.idle":"2024-06-05T05:23:03.240117Z","shell.execute_reply.started":"2024-06-05T05:23:03.227794Z","shell.execute_reply":"2024-06-05T05:23:03.238886Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### SWIN Transformer Data Load","metadata":{}},{"cell_type":"code","source":"# Previous filtering by HDJOJO\n# Keep only data that is in range 0.005 to 0.985\n# for column in CONFIG.TARGET_COLUMNS:\n#     lower_quantile = train[column].quantile(0.005)\n#     upper_quantile = train[column].quantile(0.985)  \n#     train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]\n\nCONFIG.N_TRAIN_SAMPLES = len(train)\nCONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\nCONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n\ntest = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\ntest['file_path'] = test['id'].apply(lambda s: f'/kaggle/input/planttraits2024/test_images/{s}.jpeg')\ntest['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n# test.to_pickle('test.pkl')\n\nprint('N_TRAIN_SAMPLES:', len(train), 'N_TEST_SAMPLES:', len(test))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:24:00.382517Z","iopub.execute_input":"2024-06-05T05:24:00.383826Z","iopub.status.idle":"2024-06-05T05:24:41.262968Z","shell.execute_reply.started":"2024-06-05T05:24:00.383779Z","shell.execute_reply":"2024-06-05T05:24:41.261864Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6545 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53274ec751b04c6da8e47ac685a28f9b"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"Train len:\", len(train))\nprint(\"y_train len\", len(y_train))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:23:49.017541Z","iopub.execute_input":"2024-06-05T05:23:49.018016Z","iopub.status.idle":"2024-06-05T05:23:49.024390Z","shell.execute_reply.started":"2024-06-05T05:23:49.017984Z","shell.execute_reply":"2024-06-05T05:23:49.023162Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Train len: 41797\ny_train len 41797\n","output_type":"stream"}]},{"cell_type":"code","source":"# Where did values come from?\n# Likely Mean/std dev for each channel - Check! (only for train though)\nMEAN = np.array([0.485, 0.456, 0.406])\nSTD = np.array([0.229, 0.224, 0.225])\n\nTRAIN_TRANSFORMS = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.RandomSizedCrop(\n            [448, 512],\n            CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nVALID_TRANSFORMS = A.Compose([\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nTEST_TRANSFORMS = A.Compose([\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nclass Dataset(Dataset):\n    def __init__(self, X_jpeg_bytes, y, transforms=None):\n        self.X_jpeg_bytes = X_jpeg_bytes\n        self.y = y\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.X_jpeg_bytes)\n\n    def __getitem__(self, index):\n        X_sample = self.transforms(\n            image=imageio.imread(self.X_jpeg_bytes[index]),\n        )['image']\n        y_sample = self.y[index]\n        \n        return X_sample, y_sample\n\ntrain_dataset = Dataset(\n    train['jpeg_bytes'].values,\n    y_train,\n    TRAIN_TRANSFORMS,\n)\n\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=CONFIG.BATCH_SIZE,\n    shuffle=True,\n    drop_last=True,\n    num_workers=psutil.cpu_count(),\n)\n\n\nvalid_dataset = Dataset(\n    valid['jpeg_bytes'].values,\n    valid['id'].values,\n    VALID_TRANSFORMS,\n)\n\ntest_dataset = Dataset(\n    test['jpeg_bytes'].values,\n    test['id'].values,\n    TEST_TRANSFORMS,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:24:41.265110Z","iopub.execute_input":"2024-06-05T05:24:41.265462Z","iopub.status.idle":"2024-06-05T05:24:41.284460Z","shell.execute_reply.started":"2024-06-05T05:24:41.265432Z","shell.execute_reply":"2024-06-05T05:24:41.283060Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model(\n                CONFIG.BACKBONE,\n                num_classes=CONFIG.N_TARGETS,\n                pretrained=True)  # Use pretrained SWIN Transformer model\n        \n    def forward(self, inputs):\n        return self.backbone(inputs)\n\n\nmodel = Model()\nmodel = model\n\nPATH = '/kaggle/input/simple-swin-v1-1-best-model/simple_swin_v1.1_best_model.pth'\n\n# Upload saved model\ncheckpoint = torch.load(PATH, map_location=torch.device('cpu'))\nmodel.load_state_dict(checkpoint)\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:44:25.248967Z","iopub.execute_input":"2024-06-05T05:44:25.249365Z","iopub.status.idle":"2024-06-05T05:44:27.088897Z","shell.execute_reply.started":"2024-06-05T05:44:25.249336Z","shell.execute_reply":"2024-06-05T05:44:27.087732Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Attention Maps\nInspired by Vision Transformer visualization on MNIST: https://github.com/mashaan14/VisionTransformer-MNIST/blob/main/VisionTransformer_MNIST.ipynb","metadata":{}},{"cell_type":"code","source":"# Plot and save self-attention map for first layer window attention block\n# Input: test sample index\n# Output: sample_id, original image, attention map image\n\ndef get_self_attention_map_layer0(index, dataset=test_dataset, attn_index=-2):\n    ## Get image from test set: id, image, input\n    # Image: (512, 512, 3)\n    test_sample_image = imageio.imread(dataset.X_jpeg_bytes[index])\n    # Input: Resized, normalized to input to model (3, 256, 256)\n    test_sample_input = dataset[index][0]\n    test_sample_id = dataset[index][1]\n    # Change to torch.Size([1, 3, 256, 256])\n    test_sample_input = test_sample_input.unsqueeze(0).to(CONFIG.DEVICE)\n    \n    ## Run input through first few layers before window attention\n    # input: torch.Size([1, 3, 256, 256])\n    # patch_embed: torch.Size([1, 64, 64, 96])\n    test_sample_patch_embed = model.backbone.patch_embed(test_sample_input)\n    # Run through downsample layer, Identity(), so same torch.Size([1, 64, 64, 96])\n    test_sample_downsample = model.backbone.layers[0].downsample(test_sample_patch_embed)\n    \n    ## Run input through window attention to get query, key, value (qkv)\n    window_attn = model.backbone.layers[0].blocks[0].attn\n    # torch.Size([1, 64, 64, 288])\n    # The 96 input features becomes 96 queries, 96 keys, 96 values for total of 288\n    test_sample_qkv = window_attn.qkv(test_sample_downsample)\n    \n    ## Get attention matrix\n    dim0 = 64\n    dim1 = dim0*dim0  # 4096\n    dim2 = 96\n    \n    # query, key\n    qkv = test_sample_qkv.squeeze(0).view(dim0, dim0, 3, dim2).reshape(dim1, 3, dim2)\n    q = qkv[:, 0]  # (dim1, dim2)\n    k = qkv[:, 1]\n    kT = k.permute(1, 0)  # (dim2, dim1)\n\n    # Attention matrix\n    attn_matrix = q @ kT  # (dim1, dim1)\n    \n    self_attn_image = attn_matrix[attn_index, :].reshape(dim0, dim0).detach().cpu().numpy()\n    \n    return test_sample_id, test_sample_image, self_attn_image","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:51:41.297037Z","iopub.execute_input":"2024-06-05T05:51:41.298507Z","iopub.status.idle":"2024-06-05T05:51:41.310991Z","shell.execute_reply.started":"2024-06-05T05:51:41.298463Z","shell.execute_reply":"2024-06-05T05:51:41.309694Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Folder to save images\nSELF_ATTN_FOLDER = 'test_self_attn_maps'\nif SELF_ATTN_FOLDER not in os.listdir():\n    os.mkdir(SELF_ATTN_FOLDER)\nos.listdir()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T06:26:15.052267Z","iopub.execute_input":"2024-06-05T06:26:15.052788Z","iopub.status.idle":"2024-06-05T06:26:15.065133Z","shell.execute_reply.started":"2024-06-05T06:26:15.052742Z","shell.execute_reply":"2024-06-05T06:26:15.063330Z"},"trusted":true},"execution_count":156,"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"['.virtual_documents', 'test_self_attn_maps']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Save Test Attention Maps","metadata":{}},{"cell_type":"code","source":"model.eval()\nfor i in range(50):\n    # Visualize attention weights\n    attn_index = -2  # self-attention for second-to-last pixel in image\n    test_sample_id, test_sample_image, self_attn_image = get_self_attention_map_layer0(i, test_dataset, attn_index)\n    \n    fig, ax = plt.subplots(1, 2, figsize=(12,6))\n    ax[0].imshow(test_sample_image)\n    ax[0].set_title('Plant Test Sample')\n\n    ax[1].imshow(self_attn_image)\n    ax[1].set_title('Swin Transformer First Shifted Window Attention Map')\n    \n    if f'swin_self_attn_map_{test_sample_id}.png' not in os.listdir(SELF_ATTN_FOLDER):\n        plt.savefig(f'{SELF_ATTN_FOLDER}/swin_self_attn_map_{test_sample_id}')\n    plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T06:26:26.981952Z","iopub.execute_input":"2024-06-05T06:26:26.983168Z","iopub.status.idle":"2024-06-05T06:26:56.589950Z","shell.execute_reply.started":"2024-06-05T06:26:26.983128Z","shell.execute_reply":"2024-06-05T06:26:56.588355Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"markdown","source":"### Visualize Validation Attention Map and R2 Scores","metadata":{}},{"cell_type":"code","source":"Y_MEAN = torch.tensor(y_train).mean(dim=0).to(CONFIG.DEVICE)\nEPS = torch.tensor([1e-6]).to(CONFIG.DEVICE)\nprint(Y_MEAN)\n\nTRAIT_COLS = [CONFIG.TARGET_COLUMNS[i].removesuffix(\"_mean\") for i in range(CONFIG.N_TARGETS)] \nprint(TRAIT_COLS)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T06:17:07.569247Z","iopub.execute_input":"2024-06-05T06:17:07.569769Z","iopub.status.idle":"2024-06-05T06:17:07.582155Z","shell.execute_reply.started":"2024-06-05T06:17:07.569735Z","shell.execute_reply":"2024-06-05T06:17:07.580634Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"tensor([-2.7200e-16,  3.0642e-16,  6.7999e-18, -1.6320e-17, -2.6690e-17,\n         6.3239e-17], dtype=torch.float64)\n['X4', 'X11', 'X18', 'X50', 'X26', 'X3112']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Folder to save images\nVALID_SELF_ATTN_FOLDER = 'valid_self_attn_maps'\nif VALID_SELF_ATTN_FOLDER not in os.listdir():\n    os.mkdir(VALID_SELF_ATTN_FOLDER)\nos.listdir()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T06:38:04.975736Z","iopub.execute_input":"2024-06-05T06:38:04.976219Z","iopub.status.idle":"2024-06-05T06:38:04.987205Z","shell.execute_reply.started":"2024-06-05T06:38:04.976183Z","shell.execute_reply":"2024-06-05T06:38:04.986023Z"},"trusted":true},"execution_count":167,"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"['.virtual_documents', 'valid_self_attn_maps', 'test_self_attn_maps']"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()  # Ensure outputs are consistent\n\nfor j in range(50):\n    # Get Validation Attention\n    attn_index = -2  # self-attention for second-to-last pixel in image\n    valid_sample_id, valid_sample_image, self_attn_image = get_self_attention_map_layer0(j, valid_dataset, attn_index)\n    \n    # Run valid sample image through Swin\n    with torch.no_grad():\n        y_valid_pred = model(valid_dataset[j][0].unsqueeze(0).to(CONFIG.DEVICE)).detach().cpu().numpy()\n        \n    # Get R2Score for valid sample image\n    y_valid_true = valid[valid['id'] == valid_sample_id][CONFIG.TARGET_COLUMNS].to_numpy()\n    y_valid_pred = torch.tensor(y_valid_pred, dtype=torch.float64)\n    y_valid_true = torch.tensor(y_valid_true)\n    \n    # Compute R2\n    ss_total = torch.sum((y_valid_true - Y_MEAN)**2, dim=0)\n    ss_total = torch.maximum(ss_total, EPS)\n    \n    ss_res = torch.sum((y_valid_true - y_valid_pred)**2, dim=0)\n    r2 = 1 - ss_res / ss_total\n    avg_r2 = torch.mean(r2)\n    \n    title_list1 = [f\"{TRAIT_COLS[i]}: {r2[i]:.4f}\" for i in range(CONFIG.N_TARGETS//2)]\n    title_list2 = [f\"{TRAIT_COLS[i]}: {r2[i]:.4f}\" for i in range(CONFIG.N_TARGETS//2, CONFIG.N_TARGETS)]\n    title = f\"Validation Sample R2 Scores. Average R2 = {avg_r2:.4f} \\n\" + \",   \".join(title_list1) + \"\\n\" + \",   \".join(title_list2) + \"\\n\"\n    \n    # Plot\n    fig, ax = plt.subplots(1, 2, figsize=(12,6))\n    fig.suptitle(title, fontsize=16)\n    fig.subplots_adjust(top=0.8)\n    ax[0].imshow(valid_sample_image)\n    ax[0].set_title('Plant Test Sample')\n\n    ax[1].imshow(self_attn_image)\n    ax[1].set_title('Swin Transformer First Shifted Window Attention Map')\n    \n    # Save image\n    if f'valid_swin_self_attn_map_{valid_sample_id}.png' not in os.listdir(VALID_SELF_ATTN_FOLDER):\n        plt.savefig(f'{VALID_SELF_ATTN_FOLDER}/valid_swin_self_attn_map_{valid_sample_id}')\n    plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T06:38:27.598816Z","iopub.execute_input":"2024-06-05T06:38:27.599245Z","iopub.status.idle":"2024-06-05T06:39:13.422965Z","shell.execute_reply.started":"2024-06-05T06:38:27.599212Z","shell.execute_reply":"2024-06-05T06:39:13.421738Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"markdown","source":"## Training, Valid, Testing components\n","metadata":{}},{"cell_type":"code","source":"# def get_lr_scheduler(optimizer):\n#     return torch.optim.lr_scheduler.OneCycleLR(\n#         optimizer=optimizer,\n#         max_lr=CONFIG.LR_MAX,\n#         total_steps=CONFIG.N_STEPS,\n#         pct_start=0.1,\n#         anneal_strategy='cos',\n#         div_factor=1e1,\n#         final_div_factor=1e1,\n#     )\n\n# class AverageMeter(object):\n#     def __init__(self):\n#         self.reset()\n\n#     def reset(self):\n#         self.avg = 0\n#         self.sum = 0\n#         self.count = 0\n\n#     def update(self, val):\n#         self.sum += val.sum()\n#         self.count += val.numel()\n#         self.avg = self.sum / self.count\n\n# MAE = torchmetrics.regression.MeanAbsoluteError().to('cuda')\n# R2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to('cuda')\n# LOSS = AverageMeter()\n\n# Y_MEAN = torch.tensor(y_train).mean(dim=0).to('cuda')\n# EPS = torch.tensor([1e-6]).to('cuda')\n\n# def r2_loss(y_pred, y_true):\n#     ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n#     ss_total = torch.sum((y_true - Y_MEAN)**2, dim=0)\n#     ss_total = torch.maximum(ss_total, EPS)\n#     r2 = torch.mean(ss_res / ss_total)\n#     return r2\n\n# # How is this R2 Loss?\n# LOSS_FN = nn.SmoothL1Loss() # r2_loss\n\n# optimizer = torch.optim.AdamW(\n#     params=model.parameters(),\n#     lr=CONFIG.LR_MAX,\n#     weight_decay=CONFIG.WEIGHT_DECAY,\n# )\n\n# LR_SCHEDULER = get_lr_scheduler(optimizer)\n\n# def count_parameters(model):\n#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# metrics = {\n#     'epoch': [],\n#     'loss': [],\n#     'mae': [],\n#     'r2': [],\n#     'lr': [],\n#     'training_time': [],\n#     'num_params': count_parameters(model),\n#     'valid_r2': [],\n#     'valid_mae': [],\n#     'valid_r2_loss': [],\n#     'valid_sl1_loss': []\n# }","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:36:48.971835Z","iopub.execute_input":"2024-05-30T06:36:48.972613Z","iopub.status.idle":"2024-05-30T06:36:48.991304Z","shell.execute_reply.started":"2024-05-30T06:36:48.97258Z","shell.execute_reply":"2024-05-30T06:36:48.990309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_valid_r2 = -np.inf \n\n# print(\"Start Training:\")\n# for epoch in range(CONFIG.N_EPOCHS):\n#     epoch_start_time = time.time()\n#     MAE.reset()\n#     R2.reset()\n#     LOSS.reset()\n#     model.train()\n    \n#     epoch_loss = 0\n#     epoch_mae = 0\n#     epoch_r2 = 0\n        \n#     for step, (X_batch, y_true) in enumerate(train_dataloader):\n#         X_batch = X_batch.to('cuda')\n#         y_true = y_true.to('cuda')\n#         t_start = time.perf_counter_ns()\n#         y_pred = model(X_batch)\n#         loss = LOSS_FN(y_pred, y_true)\n#         LOSS.update(loss)\n#         loss.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n#         LR_SCHEDULER.step()\n#         MAE.update(y_pred, y_true)\n#         R2.update(y_pred, y_true)\n        \n#         epoch_loss += loss.item()\n#         epoch_mae += MAE.compute().item()\n#         epoch_r2 += R2.compute().item()\n            \n#         if not CONFIG.IS_INTERACTIVE and (step+1) == CONFIG.N_STEPS_PER_EPOCH:\n#             print(\n#                 f'EPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n#                 f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n#                 f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n#             )\n#         elif CONFIG.IS_INTERACTIVE:\n#             print(\n#                 f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n#                 f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n#                 f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n#                 end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n#             )\n            \n#     epoch_training_time = time.time() - epoch_start_time\n    \n#     # Validate on validation set\n#     VALID_ROWS = []\n#     model.eval()\n\n#     for X_sample_valid, valid_id in tqdm(valid_dataset):\n#         with torch.no_grad():\n#             y_pred = model(X_sample_valid.unsqueeze(0).to('cuda')).detach().cpu().numpy()\n\n#         y_pred = SCALER.inverse_transform(y_pred).squeeze()\n#         row = {'id': valid_id}\n\n#         for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n#             if k in LOG_FEATURES:\n#                 row[k] = 10 ** v\n#             else:\n#                 row[k] = v\n\n#         VALID_ROWS.append(row)\n\n#     valid_predict_df = pd.DataFrame(VALID_ROWS)\n#     valid_y_true = torch.tensor(valid[CONFIG.TARGET_COLUMNS].to_numpy()).to('cuda')\n#     valid_y_pred = torch.tensor(valid_predict_df[CONFIG.TARGET_COLUMNS].to_numpy()).to('cuda')\n\n#     MAE_valid = torchmetrics.regression.MeanAbsoluteError().to('cuda')\n#     R2_valid = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to('cuda')\n    \n#     with torch.no_grad():\n#         valid_r2 = R2_valid(valid_y_pred, valid_y_true).item()\n#         valid_mae = MAE_valid(valid_y_pred, valid_y_true).item()\n#         valid_r2_loss = r2_loss(valid_y_pred, valid_y_true).item()\n#         valid_sl1_loss = LOSS_FN(valid_y_pred, valid_y_true).item()\n        \n        \n#         # Log metrics for this epoch\n#         metrics['epoch'].append(epoch + 1)\n#         metrics['loss'].append(epoch_loss / len(train_dataloader))\n#         metrics['mae'].append(epoch_mae / len(train_dataloader))\n#         metrics['r2'].append(epoch_r2 / len(train_dataloader))\n#         metrics['lr'].append(LR_SCHEDULER.get_last_lr()[0])\n#         metrics['training_time'].append(epoch_training_time)\n#         metrics['valid_r2'].append(valid_r2)\n#         metrics['valid_mae'].append(valid_mae)\n#         metrics['valid_r2_loss'].append(valid_r2_loss)\n#         metrics['valid_sl1_loss'].append(valid_sl1_loss)\n        \n#         # Save the model if validation R2 improves\n#         if valid_r2 > best_valid_r2:\n#             best_valid_r2 = valid_r2\n#             torch.save(model.state_dict(), 'best_model.pth')\n#             print(f'Saved Best Model at Epoch {epoch + 1} with R2: {valid_r2:.4f}')\n\n# # Save metrics to a file\n# import json\n# with open('metrics3.json', 'w') as f:\n#     json.dump(metrics, f)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:36:51.385351Z","iopub.execute_input":"2024-05-30T06:36:51.385718Z","iopub.status.idle":"2024-05-30T06:36:52.858747Z","shell.execute_reply.started":"2024-05-30T06:36:51.385691Z","shell.execute_reply":"2024-05-30T06:36:52.85703Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import json\n# import matplotlib.pyplot as plt\n\n# # Load the metrics\n# with open('metrics3.json', 'r') as f:\n#     metrics = json.load(f)\n\n# # Plotting training and validation metrics\n# fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# # Loss plot\n# axes[0, 0].plot(metrics['epoch'], metrics['loss'], label='Train Loss')\n# axes[0, 0].plot(metrics['epoch'], metrics['valid_sl1_loss'], label='Valid SL1 Loss')\n# axes[0, 0].set_title('Loss')\n# axes[0, 0].set_xlabel('Epoch')\n# axes[0, 0].set_ylabel('Loss')\n# axes[0, 0].legend()\n\n# # MAE plot\n# axes[0, 1].plot(metrics['epoch'], metrics['mae'], label='Train MAE')\n# axes[0, 1].plot(metrics['epoch'], metrics['valid_mae'], label='Valid MAE')\n# axes[0, 1].set_title('Mean Absolute Error (MAE)')\n# axes[0, 1].set_xlabel('Epoch')\n# axes[0, 1].set_ylabel('MAE')\n# axes[0, 1].legend()\n\n# # R2 plot\n# axes[1, 0].plot(metrics['epoch'], metrics['r2'], label='Train R2')\n# axes[1, 0].plot(metrics['epoch'], metrics['valid_r2'], label='Valid R2')\n# axes[1, 0].set_title('R2 Score')\n# axes[1, 0].set_xlabel('Epoch')\n# axes[1, 0].set_ylabel('R2 Score')\n# axes[1, 0].legend()\n\n# # Learning rate plot\n# axes[1, 1].plot(metrics['epoch'], metrics['lr'], label='Learning Rate')\n# axes[1, 1].set_title('Learning Rate')\n# axes[1, 1].set_xlabel('Epoch')\n# axes[1, 1].set_ylabel('Learning Rate')\n# axes[1, 1].legend()\n\n# plt.tight_layout()\n# plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Validate on validation set\n# VALID_ROWS = []\n# model.eval()\n\n# for X_sample_valid, valid_id in tqdm(valid_dataset):\n#     with torch.no_grad():\n#         y_pred = model(X_sample_valid.unsqueeze(0).to('cuda')).detach().cpu().numpy()\n    \n#     y_pred = SCALER.inverse_transform(y_pred).squeeze()\n#     row = {'id': valid_id}\n    \n#     for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n#         if k in LOG_FEATURES:\n#             row[k] = 10 ** v\n#         else:\n#             row[k] = v\n\n#     VALID_ROWS.append(row)\n    \n# valid_predict_df = pd.DataFrame(VALID_ROWS)\n# print(valid_predict_df.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # valid_y_true\n# print(valid[['id'] + CONFIG.TARGET_COLUMNS].head())\n# valid_y_true = torch.tensor(valid[CONFIG.TARGET_COLUMNS].to_numpy()).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T02:00:49.061681Z","iopub.execute_input":"2024-05-23T02:00:49.062126Z","iopub.status.idle":"2024-05-23T02:00:49.076088Z","shell.execute_reply.started":"2024-05-23T02:00:49.062094Z","shell.execute_reply":"2024-05-23T02:00:49.074358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Evaluate valid scores\n# valid_y_pred = torch.tensor(valid_predict_df[CONFIG.TARGET_COLUMNS].to_numpy()).to('cuda')\n\n# with torch.no_grad():\n#     # Calculate R2 Loss\n#     print(\"Validation R2 Loss (using r2_loss):\", r2_loss(valid_y_pred, valid_y_true))\n\n#     # Loss function (smooth L1 loss)\n#     valid_loss = LOSS_FN(valid_y_pred, valid_y_true)\n#     print(\"Validation loss (Smooth L1 loss): \", valid_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALID_Y_MEAN = torch.tensor(y_train).mean(dim=0).to('cuda')\n\n# def r2_loss_valid(y_pred, y_true):\n#     ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n#     ss_total = torch.sum((y_true - VALID_Y_MEAN)**2, dim=0)\n#     ss_total = torch.maximum(ss_total, torch.tensor([1e-6]))\n#     r2 = torch.mean(ss_res / ss_total)\n#     return r2\n\n# print(\"R2 Score valid (using r2_loss_valid):\", 1 - r2_loss_valid(valid_y_pred, valid_y_true))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T02:13:27.600788Z","iopub.execute_input":"2024-05-23T02:13:27.601294Z","iopub.status.idle":"2024-05-23T02:13:27.615198Z","shell.execute_reply.started":"2024-05-23T02:13:27.601261Z","shell.execute_reply":"2024-05-23T02:13:27.614149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Scratch code to test R2 loss: random produced around R2 score = -92\n# # v_len = len(valid_y_true)\n# # train_y_true = torch.tensor(train[0:v_len][CONFIG.TARGET_COLUMNS].to_numpy())\n# # print(\"Train and valid R2 score:\", 1 - r2_loss_valid(valid_y_true, train_y_true))\n\n# MAE_valid = torchmetrics.regression.MeanAbsoluteError().to('cuda')\n# R2_valid = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to('cuda')\n\n# print(\"Torch R2 valid:\", R2_valid(valid_y_pred, valid_y_true))\n# print(\"Torch MAE valid:\", MAE_valid(valid_y_pred, valid_y_true))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T02:23:56.486144Z","iopub.execute_input":"2024-05-23T02:23:56.486743Z","iopub.status.idle":"2024-05-23T02:23:56.554094Z","shell.execute_reply.started":"2024-05-23T02:23:56.486704Z","shell.execute_reply":"2024-05-23T02:23:56.552215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Predict on test set\n# SUBMISSION_ROWS = []\n# model.eval()\n\n# for X_sample_test, test_id in tqdm(test_dataset):\n#     with torch.no_grad():\n#         y_pred = model(X_sample_test.unsqueeze(0).to('cuda')).detach().cpu().numpy()\n    \n#     y_pred = SCALER.inverse_transform(y_pred).squeeze()\n#     row = {'id': test_id}\n    \n#     for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n#         if k in LOG_FEATURES:\n#             row[k.replace('_mean', '')] = 10 ** v\n#         else:\n#             row[k.replace('_mean', '')] = v\n\n#     SUBMISSION_ROWS.append(row)\n    \n# submission_df = pd.DataFrame(SUBMISSION_ROWS)\n# print(submission_df.head())\n# submission_df.to_csv('submission.csv', index=False)\n# print(\"Submit!\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T01:59:25.510075Z","iopub.status.idle":"2024-05-14T01:59:25.510566Z","shell.execute_reply.started":"2024-05-14T01:59:25.510303Z","shell.execute_reply":"2024-05-14T01:59:25.510334Z"},"trusted":true},"execution_count":null,"outputs":[]}]}